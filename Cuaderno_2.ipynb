{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58082239-b4e7-4ea7-9915-40f1e4474af5",
   "metadata": {},
   "source": [
    "# Predicción de aprobación de curso de matemáticas usando árboles de decisión\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **scikit-learn** es una librería que cuenta con algoritmos de clasificación, regresión, clustering y reducción de dimensionalidad. Además, presenta la compatibilidad con otras librerías como NumPy, SciPy y matplotlib.\n",
    "\n",
    "*   **Pandas** es una librería de Python especializada en la manipulación y el análisis de datos. Ofrece estructuras de datos y operaciones para manipular tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e7799-6919-4ab7-9bd6-25028b1a370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se cargan los datos del archivo CSV a un **dataframe**. Un dataframe es una estructura de datos con filas y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94627e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('student_performance.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se muestra información general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos.shape)\n",
    "print(datos.info())\n",
    "print(datos.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se identifican las columnas numéricas y categóricas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_numericas = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'goout', 'Walc', 'health']\n",
    "columnas_categoricas = ['sex', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'internet', 'romantic']\n",
    "print(\"Columnas numéricas:\", columnas_numericas)\n",
    "print(\"Columnas categóricas:\", columnas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se normalizan las variables numéricas usando **StandardScaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "datos[columnas_numericas] = scaler.fit_transform(datos[columnas_numericas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se codifican las variables categóricas usando **LabelEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas_categoricas:\n",
    "    le = LabelEncoder()\n",
    "    datos[col] = le.fit_transform(datos[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se separan las características (X) de la variable a predecir (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos.drop('approved', axis=1)\n",
    "Y = datos['approved']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se divide el dataset en 80% para entrenamiento y 20% para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(\"Tamaño conjunto de entrenamiento:\", X_train.shape[0])\n",
    "print(\"Tamaño conjunto de prueba:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión con criterio 'gini'\n",
    "*   Se crean 5 árboles con max_depth desde 2 hasta 10 con incrementos de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_gini = []\n",
    "\n",
    "for depth in [2, 4, 6, 8, 10]:\n",
    "    modelo = tree.DecisionTreeClassifier(criterion='gini', max_depth=depth, random_state=42)\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predicciones)\n",
    "    resultados_gini.append({'max_depth': depth, 'criterion': 'gini', 'accuracy': accuracy})\n",
    "    print(f\"max_depth={depth}, criterion='gini': Accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Tabla de resultados para criterio 'gini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_gini = pd.DataFrame(resultados_gini)\n",
    "tabla_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión con criterio 'entropy'\n",
    "*   Se crean 5 árboles con max_depth desde 2 hasta 10 con incrementos de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_entropy = []\n",
    "\n",
    "for depth in [2, 4, 6, 8, 10]:\n",
    "    modelo = tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predicciones)\n",
    "    resultados_entropy.append({'max_depth': depth, 'criterion': 'entropy', 'accuracy': accuracy})\n",
    "    print(f\"max_depth={depth}, criterion='entropy': Accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Tabla de resultados para criterio 'entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_entropy = pd.DataFrame(resultados_entropy)\n",
    "tabla_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se combinan ambos resultados para identificar el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_resultados = pd.concat([tabla_gini, tabla_entropy], ignore_index=True)\n",
    "todos_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor = todos_resultados.loc[todos_resultados['accuracy'].idxmax()]\n",
    "print(\"\\nMejor modelo:\")\n",
    "print(f\"max_depth: {int(mejor['max_depth'])}\")\n",
    "print(f\"criterion: {mejor['criterion']}\")\n",
    "print(f\"accuracy: {mejor['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros del mejor árbol de decisión\n",
    "\n",
    "Después de evaluar 10 configuraciones diferentes, los hiperparámetros que proporcionan el mayor accuracy son los mostrados en la celda anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación con hiperparámetro adicional: min_samples_split\n",
    "\n",
    "*   Se selecciona el hiperparámetro **min_samples_split** que controla el número mínimo de muestras necesarias para dividir un nodo interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_max_depth = int(mejor['max_depth'])\n",
    "mejor_criterion = mejor['criterion']\n",
    "mejor_accuracy = mejor['accuracy']\n",
    "\n",
    "print(f\"Configuración base del mejor modelo:\")\n",
    "print(f\"max_depth={mejor_max_depth}, criterion='{mejor_criterion}'\")\n",
    "print(f\"Accuracy base: {mejor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se prueban dos valores diferentes de min_samples_split: 10 y 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_adicional = []\n",
    "\n",
    "# Modelo base (min_samples_split=2 por defecto)\n",
    "resultados_adicional.append({\n",
    "    'min_samples_split': 2,\n",
    "    'accuracy': mejor_accuracy,\n",
    "    'diferencia': 0.0\n",
    "})\n",
    "\n",
    "# Variaciones de min_samples_split\n",
    "for min_samples in [10, 50]:\n",
    "    modelo = tree.DecisionTreeClassifier(\n",
    "        criterion=mejor_criterion,\n",
    "        max_depth=mejor_max_depth,\n",
    "        min_samples_split=min_samples,\n",
    "        random_state=42\n",
    "    )\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predicciones)\n",
    "    diferencia = accuracy - mejor_accuracy\n",
    "    \n",
    "    resultados_adicional.append({\n",
    "        'min_samples_split': min_samples,\n",
    "        'accuracy': accuracy,\n",
    "        'diferencia': diferencia\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nmin_samples_split={min_samples}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Diferencia con modelo base: {diferencia:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_adicional = pd.DataFrame(resultados_adicional)\n",
    "tabla_adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del hiperparámetro min_samples_split\n",
    "\n",
    "El hiperparámetro **min_samples_split** especifica el número mínimo de muestras requeridas para dividir un nodo interno del árbol. \n",
    "\n",
    "**Valores probados:**\n",
    "- min_samples_split = 2 (valor por defecto)\n",
    "- min_samples_split = 10\n",
    "- min_samples_split = 50\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "Al modificar el valor de min_samples_split se observa que:\n",
    "\n",
    "- Si el accuracy **aumenta**: el modelo está mejorando su capacidad de generalización al evitar divisiones con pocas muestras que podrían estar capturando ruido.\n",
    "\n",
    "- Si el accuracy **disminuye**: el modelo pierde capacidad predictiva porque no puede realizar divisiones necesarias para capturar patrones importantes en los datos.\n",
    "\n",
    "- Si el accuracy **se mantiene**: el valor de min_samples_split no afecta significativamente al modelo con la configuración actual de max_depth.\n",
    "\n",
    "Un valor más alto de min_samples_split hace que el árbol sea más conservador en sus divisiones, lo que puede ayudar a prevenir el sobreajuste pero también puede resultar en un modelo más simple que pierde precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Se calcula el accuracy, la sensibilidad y especificidad para el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo\n",
    "modelo_final = tree.DecisionTreeClassifier(\n",
    "    criterion=mejor_criterion,\n",
    "    max_depth=mejor_max_depth,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_final.fit(X_train, Y_train)\n",
    "predicciones_final = modelo_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(Y_test, predicciones_final)\n",
    "sensibilidad = recall_score(Y_test, predicciones_final, pos_label=1)\n",
    "especificidad = recall_score(Y_test, predicciones_final, pos_label=0)\n",
    "\n",
    "print(\"Accuracy=\", accuracy)\n",
    "print(\"Sensibilidad=\", sensibilidad)\n",
    "print(\"Especificidad=\", especificidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Matriz de confusión del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(Y_test, predicciones_final)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Gráfico de comparación de accuracy entre criterios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([2, 4, 6, 8, 10], tabla_gini['accuracy'], marker='o', label='Gini', linewidth=2)\n",
    "plt.plot([2, 4, 6, 8, 10], tabla_entropy['accuracy'], marker='s', label='Entropy', linewidth=2)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparación de Accuracy por Criterio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
