# Predicci√≥n de Aprobaci√≥n de Curso de Matem√°ticas - Machine Learning

## üìã Informaci√≥n General

Este repositorio contiene dos proyectos de Machine Learning desarrollados para predecir si un estudiante aprobar√° un curso de matem√°ticas. El an√°lisis se realiza utilizando un dataset de 1044 estudiantes con 17 atributos que incluyen informaci√≥n demogr√°fica, educativa y de h√°bitos de estudio.

**Universidad del Valle**  
**Escuela de Ingenier√≠a de Sistemas y Computaci√≥n**  
**Curso:** Inteligencia Artificial  
**Autores:** 
- Juan Sebastian Sierra - 202343656
- Jhoan Sebastian Fernandez - 2222772

---

## üéØ Objetivo del Proyecto

El proyecto tiene como objetivo desarrollar y comparar dos t√©cnicas de Machine Learning para predecir la aprobaci√≥n de estudiantes en un curso de matem√°ticas:

1. **Redes Neuronales Artificiales (MLP)** - Cuaderno 1
2. **√Årboles de Decisi√≥n** - Cuaderno 2

La variable objetivo es `approved`, que toma el valor 1 cuando el estudiante aprueba el curso y 0 en caso contrario.

---

## üìä Dataset

### Descripci√≥n del Dataset
El dataset `student_performance.csv` contiene informaci√≥n de 1044 estudiantes con los siguientes atributos:

#### Variables Categ√≥ricas:
- **sex**: Sexo del estudiante (F/M)
- **famsize**: Tama√±o de familia (LE3: ‚â§3 personas, GT3: >3 personas)
- **Pstatus**: Estado de convivencia de los padres (T: juntos, A: separados)
- **Mjob**: Trabajo de la madre (teacher, health, services, at_home, other)
- **Fjob**: Trabajo del padre (teacher, health, services, at_home, other)
- **internet**: Acceso a internet en casa (yes/no)
- **romantic**: En relaci√≥n rom√°ntica (yes/no)

#### Variables Num√©ricas:
- **age**: Edad (15-22 a√±os)
- **Medu**: Nivel educativo de la madre (0-4)
- **Fedu**: Nivel educativo del padre (0-4)
- **traveltime**: Tiempo de traslado a la instituci√≥n (1-4)
- **studytime**: Tiempo de estudio semanal (1-4)
- **failures**: N√∫mero de veces que ha reprobado el curso (0-4)
- **goout**: Frecuencia de salidas con amigos (1-5)
- **Walc**: Consumo de alcohol en fin de semana (1-5)
- **health**: Estado de salud actual (1-5)

#### Variable Objetivo:
- **approved**: Indica si aprob√≥ el curso (0: No, 1: S√≠)

---

## üìì Notebooks Desarrollados

### üìò Cuaderno 1: Redes Neuronales (MLP)

**Archivo:** `Cuaderno_1.ipynb`

#### Contenido:
1. **Carga y exploraci√≥n de datos**: Lectura del archivo CSV y an√°lisis exploratorio
2. **Preprocesamiento**:
   - Divisi√≥n de datos: 80% entrenamiento, 20% prueba
   - Normalizaci√≥n de variables num√©ricas con StandardScaler
   - Codificaci√≥n de variables categ√≥ricas con OneHotEncoder
3. **Construcci√≥n de modelos**: 5 redes neuronales con diferentes configuraciones:
   - Variaci√≥n de capas ocultas y neuronas por capa
   - Diferentes solvers (adam, sgd, lbfgs)
   - Funciones de activaci√≥n variadas (relu, tanh, logistic)
4. **Evaluaci√≥n**: Tabla comparativa de accuracy para los 5 modelos
5. **Optimizaci√≥n**: Identificaci√≥n del mejor modelo y experimentaci√≥n con hiperpar√°metro adicional (alpha)
6. **M√©tricas finales**: Accuracy, Sensibilidad, Especificidad y MAE

#### Modelos Implementados:
Los modelos var√≠an en arquitectura, desde redes simples hasta configuraciones m√°s complejas, permitiendo comparar el rendimiento y encontrar la configuraci√≥n √≥ptima.

---

### üìó Cuaderno 2: √Årboles de Decisi√≥n

**Archivo:** `Cuaderno_2.ipynb`

#### Contenido:
1. **Carga y exploraci√≥n de datos**: Lectura del archivo CSV y an√°lisis inicial
2. **Preprocesamiento**:
   - Divisi√≥n de datos: 80% entrenamiento, 20% prueba
   - Normalizaci√≥n de variables num√©ricas con StandardScaler
   - Codificaci√≥n de variables categ√≥ricas con LabelEncoder
3. **√Årboles con criterio Gini**:
   - 5 √°rboles con max_depth de 2 a 10 (incrementos de 2)
   - Tabla comparativa de resultados
4. **√Årboles con criterio Entropy**:
   - 5 √°rboles con max_depth de 2 a 10 (incrementos de 2)
   - Tabla comparativa de resultados
5. **Identificaci√≥n del mejor modelo**: Comparaci√≥n entre ambos criterios
6. **Experimentaci√≥n adicional**: Prueba del hiperpar√°metro min_samples_split
7. **M√©tricas y visualizaci√≥n**:
   - Accuracy, Sensibilidad, Especificidad
   - Matriz de confusi√≥n
   - Gr√°fico comparativo de accuracy por criterio

#### An√°lisis Implementado:
El notebook incluye an√°lisis detallado sobre c√≥mo el hiperpar√°metro min_samples_split afecta el rendimiento del modelo, ayudando a prevenir el sobreajuste.

---

## üõ†Ô∏è Requisitos e Instalaci√≥n

### Dependencias Principales:
```python
scikit-learn
pandas
numpy
matplotlib
```

### Instalaci√≥n:

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/prediccion-estudiantes-ml.git
cd prediccion-estudiantes-ml

# Instalar dependencias
pip install scikit-learn pandas numpy matplotlib
```

---

## üöÄ C√≥mo Utilizar

### Opci√≥n 1: Jupyter Notebook (Local)

1. Aseg√∫rate de tener Jupyter instalado:
```bash
pip install jupyter
```

2. Coloca el archivo `student_performance.csv` en el mismo directorio que los notebooks

3. Inicia Jupyter Notebook:
```bash
jupyter notebook
```

4. Abre el notebook deseado (`Cuaderno_1.ipynb` o `Cuaderno_2.ipynb`)

5. Ejecuta las celdas secuencialmente desde el principio

### Opci√≥n 2: Google Colab

1. Sube el archivo `student_performance.csv` a tu Google Drive o c√°rgalo directamente en Colab

2. Abre el notebook en Google Colab

3. Si el archivo CSV est√° en Google Drive, monta tu Drive:
```python
from google.colab import drive
drive.mount('/content/drive')
```

4. Ajusta la ruta del archivo CSV seg√∫n corresponda

5. Ejecuta todas las celdas

### Estructura del Proyecto

```
‚îú‚îÄ‚îÄ Cuaderno_1.ipynb          # Notebook de Redes Neuronales
‚îú‚îÄ‚îÄ Cuaderno_2.ipynb          # Notebook de √Årboles de Decisi√≥n
‚îú‚îÄ‚îÄ student_performance.csv   # Dataset (debe agregarse)
‚îú‚îÄ‚îÄ Informe_Machine_learning.pdf  # Documento con especificaciones
‚îî‚îÄ‚îÄ README.md                 # Este archivo
```

---

## üìà Resultados Esperados

### Cuaderno 1 - Redes Neuronales:
- Tabla con accuracy de 5 modelos diferentes
- Identificaci√≥n del modelo con mejor rendimiento
- An√°lisis del impacto del hiperpar√°metro alpha
- M√©tricas completas: Accuracy, Sensibilidad, Especificidad, MAE

### Cuaderno 2 - √Årboles de Decisi√≥n:
- Dos tablas comparativas (criterio Gini y Entropy)
- Identificaci√≥n del mejor modelo seg√∫n max_depth y criterion
- An√°lisis del hiperpar√°metro min_samples_split
- Matriz de confusi√≥n
- Visualizaci√≥n gr√°fica comparativa de accuracies

---

## üìä M√©tricas de Evaluaci√≥n

Ambos notebooks calculan las siguientes m√©tricas:

- **Accuracy**: Proporci√≥n de predicciones correctas
- **Sensibilidad (Recall)**: Proporci√≥n de casos positivos correctamente identificados
- **Especificidad**: Proporci√≥n de casos negativos correctamente identificados
- **MAE** (solo Cuaderno 1): Error absoluto medio

---

## üîç Aspectos T√©cnicos Importantes

### Preprocesamiento de Datos:

**Cuaderno 1:**
- Normalizaci√≥n: StandardScaler para variables num√©ricas
- Codificaci√≥n: OneHotEncoder para variables categ√≥ricas

**Cuaderno 2:**
- Normalizaci√≥n: StandardScaler para variables num√©ricas
- Codificaci√≥n: LabelEncoder para variables categ√≥ricas

### Divisi√≥n de Datos:
Ambos notebooks utilizan:
- 80% para entrenamiento
- 20% para pruebas
- random_state=42 para reproducibilidad

---

## üìù Notas Adicionales

- Los notebooks est√°n dise√±ados para ejecutarse de forma secuencial
- Se recomienda ejecutar todas las celdas en orden
- Los modelos utilizan semillas aleatorias (random_state) para garantizar reproducibilidad
- Cada notebook incluye an√°lisis y comentarios explicativos en celdas de markdown

---

## üìñ Referencias

- [Documentaci√≥n scikit-learn - MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [Documentaci√≥n scikit-learn - DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
- [Documentaci√≥n Pandas](https://pandas.pydata.org/docs/)

---

## üìÑ Licencia

Este proyecto es de uso acad√©mico para el curso de Inteligencia Artificial de la Universidad del Valle.

---

## ü§ù Contribuciones

Este es un proyecto acad√©mico. Para cualquier consulta o sugerencia, contactar a los autores a trav√©s de la Universidad del Valle.

---

**√öltima actualizaci√≥n:** Diciembre 2024
